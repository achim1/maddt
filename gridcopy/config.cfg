# configuration file for gridftp_copy2

[tmpdir]
# specify a tmp dir - content will be managed automatically
tmpdir=FIXME

[madison_gsiftp]
# gridftp host
remote_gsiftp_host=gsiftp://gridftp.icecube.wisc.edu

[zeuthen_gsiftp]
# the local ports via grid to the storage elements
# these might be different depending on the storage system
# so remember to not forget your coin if you want to copy to
# Zeuthen lustre system

# gridftp_host for dcache
local_gsiftp_host=gsiftp://gridftp.ifh.de/pnfs/ifh.de

# do not forget your coin if you want to access lustre
#local_gsiftp_host=gsiftp://styx.ifh.de


[job_management]
#FIXME
local_csum_script=scripts/calc_sha1.sh

# how many jobs should be in the queue for the local cluster?
max_jobs_on_local_cluster=100000
# how many checksums should be calculated per job? 
max_csum_per_cluster_job=25

# how many files per copyjob?
files_per_job=250

[globus_url_options]
# specify the parameters for globus-url-copy jobs 

parallel=64
cc=100
tcp_bs=8M
bs=32M
rst_retries=3
rst_interval=0

[advanced_options]
# should broken files be deleted automatically?
auto_delete_corrupt_files=True
# if this is larger than 1, "IGNORED" flag will be set to the database after the last try
copy_retries=0


[logging]
# specify log level and directory for logs
# 10 = debug, 20 = info
loglevel=20
logdir=FIXME

[database_query]
# modify the query string for the get_files method
dataset_id=1888 
# 1888 - for 2016 data
# 1883 is a correct one for 2015, 1866 - for old data (icecube 12 retransfer)
#dataset_id=1866
#dataset_id=1871
limit=1000
#limit=1000
#limit=600
#limit=10000
